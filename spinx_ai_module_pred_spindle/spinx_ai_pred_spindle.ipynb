{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict spindle\n",
    "\n",
    "Notebook to use trained models for predicting 6 different profiles by detecting its precise location and contour. \n",
    "\n",
    "### 1) Load dependancies\n",
    "A complete list of key libraries are stored in `requirements.txt`. To install all depandancies, copy the library folder to the conda enviroment:\n",
    "\n",
    "`ml_env_prediction`\n",
    "\n",
    "This enviroment can also be used for measurements.\n",
    "\n",
    "### 2) Select profile (user input)\n",
    "\n",
    "The user define the profile to load the correct model for prediction:\n",
    "`profiles = [\"CellMembrane\", \"Spindle\"]`\n",
    "which is equivalent to:\n",
    "\n",
    "    \"CellMembrane\" = 0\n",
    "    \"Spindle\" = 1\n",
    "\n",
    "\n",
    "### 3) Load configuration settings\n",
    "This will load the config file with the required model settings to use the model for prediction on new images.\n",
    "\n",
    "### 4) Import image folder (Export folder will be generated automatically)\n",
    "The user selects the folder with images for import. Supported file formats are: `*.png, *.jpg, *.jpeg, *.tif`\n",
    "\n",
    "### 5) Execute inference and visualize prediction results\n",
    "Run the model on all images and produce visual inspection to evaluate segmentation results.\n",
    "\n",
    "### 6) Property table\n",
    "Save the prediction in the following format:\n",
    "    |-binary mask\n",
    "    |-semantic mask\n",
    "    |-overlay\n",
    "    .csv sheet\n",
    "\n",
    "The .csv sheet contains information such as:\n",
    "1. bounding box coordinates for each object\n",
    "2. (x,y) centroids\n",
    "3. Computational run time\n",
    "\n",
    "# -------------\n",
    "### 7). Restart kernel after each profile\n",
    "# -------------\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Prediction pipeline for SpinX\n",
    "    Author: David Dang\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import sys\n",
    "import colorsys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import time\n",
    "import skimage\n",
    "from skimage.color import rgb2gray, gray2rgb, label2rgb\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import exposure, img_as_ubyte\n",
    "from natsort import natsorted\n",
    "import termtables as tt # Print table\n",
    "from statistics import stdev # Statistics\n",
    "import pandas as pd\n",
    "import cv2\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.getcwd()\n",
    "print(ROOT_DIR)\n",
    "# Import Model\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Select profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of different profiles\n",
    "profiles = [\"CellMembrane\", \"Spindle\"]\n",
    "#####################    USER INPUT    #####################\n",
    "############################################################\n",
    "user_profile = profiles[1]\n",
    "# Select profile: [0 ,1]\n",
    "############################################################\n",
    "\n",
    "\n",
    "# IMPLEMENTED IN APEER UI\n",
    "# Use condition to remove unwanted objects\n",
    "#condition = 1\n",
    "# Define conditions Upper bound = (9.044 pixel/micron x 20micron)^2\n",
    "#object_size = 20000\n",
    "#min_score = 0.92 # 0.96 # AP\n",
    "\n",
    "# Keep segmented objects with respect to timeframe one (based on centroid distance)\n",
    "#time_lapse = 1\n",
    "#n_frames = 21\n",
    "#n_slices = 3\n",
    "\n",
    "# Turn plot off for faster processing (reduces run time per image by ~1sec)\n",
    "plot_on = 0\n",
    "\n",
    "if user_profile == \"CellMembrane\":\n",
    "    from samples import cell_membrane\n",
    "    # Load config file\n",
    "    config = cell_membrane.CustomConfig()\n",
    "    #VAL_DIR = os.path.join(ROOT_DIR, \"datasets/cell_membrane\")\n",
    "    # Load validation dataset\n",
    "    dataset = cell_membrane.CustomDataset()\n",
    "    #dataset.load_Custom(VAL_DIR, \"val\")\n",
    "    dataset.add_class(\"cell_membrane\", 1, \"cell_membrane\") # Add new class\n",
    "    # Must call before using the dataset\n",
    "    dataset.prepare()\n",
    "elif user_profile == \"Spindle\":\n",
    "    from samples import spindle\n",
    "    # Load config file\n",
    "    config = spindle.CustomConfig()\n",
    "    #VAL_DIR = os.path.join(ROOT_DIR, \"datasets/spindle\")\n",
    "    # Load validation dataset\n",
    "    dataset = spindle.CustomDataset()\n",
    "    #dataset.load_Custom(VAL_DIR, \"val\")\n",
    "    dataset.add_class(\"spindle\", 1, \"spindle\") # Add new class\n",
    "    # Must call before using the dataset\n",
    "    dataset.prepare()\n",
    "print('### Selected profile: ' + user_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load configuration settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Device to load the neural network on.\n",
    "DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imclearborder(imgBW, radius):\n",
    "    \"\"\"\n",
    "    Remove all border components in a binary image. Radius defines\n",
    "    the distance between the image border and object.\n",
    "    \"\"\"\n",
    "    # Given a black and white image, first find all of its contours\n",
    "    imgBWcopy = imgBW.copy()\n",
    "    contours,hierarchy = cv2.findContours(imgBWcopy.copy(), cv2.RETR_LIST, \n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get dimensions of image\n",
    "    imgRows = imgBW.shape[0]\n",
    "    imgCols = imgBW.shape[1]    \n",
    "\n",
    "    contourList = [] # ID list of contours that touch the border\n",
    "\n",
    "    # For each contour...|\n",
    "    for idx in np.arange(len(contours)):\n",
    "        # Get the i'th contour\n",
    "        cnt = contours[idx]\n",
    "\n",
    "        # Look at each point in the contour\n",
    "        for pt in cnt:\n",
    "            rowCnt = pt[0][1]\n",
    "            colCnt = pt[0][0]\n",
    "\n",
    "            # If this is within the radius of the border\n",
    "            # this contour goes bye bye!\n",
    "            check1 = (rowCnt >= 0 and rowCnt < radius) or (rowCnt >= imgRows-1-radius and rowCnt < imgRows)\n",
    "            check2 = (colCnt >= 0 and colCnt < radius) or (colCnt >= imgCols-1-radius and colCnt < imgCols)\n",
    "\n",
    "            if check1 or check2:\n",
    "                contourList.append(idx)\n",
    "                break\n",
    "\n",
    "    for idx in contourList:\n",
    "        cv2.drawContours(imgBWcopy, contours, idx, (0,0,0), -1)\n",
    "\n",
    "    return imgBWcopy\n",
    "\n",
    "\n",
    "def addInnerContour(crop_obj_mask, mask_inner):\n",
    "    \"\"\"\n",
    "    Take the inner mask, invert it and put it back\n",
    "    to the original mask.\n",
    "    \"\"\"\n",
    "    # Invert the object to embedded the filled contour in the original mask\n",
    "    mask_invert = 255 - mask_inner\n",
    "    # Convert uint8 [0 - 255] to [0 - 1]\n",
    "    mask_inner_bl = mask_invert/255\n",
    "    # Convert original cropped mask to [0 - 1]\n",
    "    crop_obj_mask_bl = crop_obj_mask/255\n",
    "    update_mask = mask_inner_bl * crop_obj_mask_bl\n",
    "    # Convert back to uint8\n",
    "    update_mask = np.asarray(update_mask*255).astype('uint8')\n",
    "    return update_mask\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def binarize(img):\n",
    "    # Binarize image\n",
    "    img_gray = rgb2gray(img)\n",
    "    # Binarize image\n",
    "    bw = img > 0\n",
    "    return bw\n",
    "\n",
    "def grayToRgb(im):\n",
    "    # I think this will be slow\n",
    "    w, h = im.shape\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = im\n",
    "    ret[:, :, 1] = im\n",
    "    ret[:, :, 2] = im\n",
    "    return ret\n",
    "\n",
    "def get_fname(s, file_ext):\n",
    "    \"\"\"\n",
    "    Extract filename from a URL\n",
    "    Input: String and the file extension\n",
    "    \"\"\"\n",
    "    start = s.rfind(\"/\") + len(\"/\")\n",
    "    end = s.find(file_ext)\n",
    "    substring = s[start:end+len(file_ext)]\n",
    "    return substring\n",
    "\n",
    "def check_model_name(model_file_name, model_name):\n",
    "    \"\"\"\n",
    "    Check filename of the user model (e.g. spinx_model_cell_membrane_01234.h5)\n",
    "    prefix_spinx: spinx_model\n",
    "    model_spinx: cell_membrane\n",
    "    epoch_spinx: 01234\n",
    "    \"\"\"\n",
    "    # Get file extension\n",
    "    _, ext = os.path.splitext(model_file_name)\n",
    "    # Get prefix\n",
    "    prefix_spinx = 'spinx_model'\n",
    "    prefix_user = model_file_name[:len(prefix_spinx)] # + 1 to include '_'\n",
    "    # Get model name\n",
    "    model_spinx = model_name\n",
    "    model_user = model_file_name[len(prefix_spinx) + 1:len(prefix_spinx) + 1 + len(model_name)]\n",
    "    # Get number of epoch\n",
    "    epoch_spinx = '1234' # 4-digit example\n",
    "    epoch_user = model_file_name[len(prefix_spinx) + 1 + len(model_spinx) + 1:\n",
    "                                 len(prefix_spinx) + 1 + len(model_spinx) + 1 + len(epoch_spinx)] # Epoch must be 4 digit number\n",
    "    if prefix_spinx == prefix_user:\n",
    "        print('Prefix matches')\n",
    "    else:\n",
    "        prefix_user = prefix_spinx\n",
    "        \n",
    "    if model_spinx == model_user:\n",
    "        print('Model name matches')\n",
    "    else:\n",
    "        model_user = model_name\n",
    "    \n",
    "    if len(epoch_user) == len(epoch_spinx) and epoch_user.isdigit():\n",
    "        print('4-digits match')\n",
    "    else:\n",
    "        epoch_user = epoch_spinx\n",
    "    \n",
    "    # Build file name\n",
    "    model_full_name = prefix_user + '_' + model_user + '_' + epoch_user + ext\n",
    "    return model_full_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinX():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def LoadImageList(self, img_list, index):\n",
    "        \"\"\"\n",
    "        Input: A list with image path to all images; index.\n",
    "        Output: Read i-th image from the list.\n",
    "        \"\"\"\n",
    "        file_path = img_list[index]\n",
    "        # Obtain filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        # Get only filename without path or extension\n",
    "        #filename_wo_ext = os.path.splitext(filename)[0]\n",
    "        # Read image\n",
    "        img = skimage.io.imread(file_path)\n",
    "        if len(img.shape)==3:\n",
    "            img = rgb2gray(img)\n",
    "        elif len(img.shape)>3:\n",
    "            print('Input image dimension is larger than 3')\n",
    "        output = np.array(img)\n",
    "        return output, filename\n",
    "    \n",
    "    def Convert5D(self, img_list, n_slices, n_time):\n",
    "        \"\"\"\n",
    "        Input: A list with image path to all images, number of z-slices; Number of frames.\n",
    "        Output: 5D array with (H x W x D x T x C) or (Y x X x Z x T x C).\n",
    "        Z refers to -slices, T refers to time points, C refers to cell id.\n",
    "        \"\"\"\n",
    "        temp_array = []\n",
    "        name_list = []\n",
    "        n_cells = len(img_list)//(n_slices*n_time)\n",
    "        for i in range(len(img_list)):\n",
    "            mask, name_mask = self.LoadImageList(img_list, i)\n",
    "            # Read the image dimensions from first image\n",
    "            if i == 1:\n",
    "                # Image info\n",
    "                img_height = mask.shape[0] # Y\n",
    "                img_width = mask.shape[1] # X\n",
    "                temp_array.append(mask)\n",
    "                name_list.append(name_mask)\n",
    "            else:\n",
    "                temp_array.append(mask)\n",
    "                name_list.append(name_mask)\n",
    "           \n",
    "        # use \"F\" Fortran for correct order\n",
    "        array5d = np.dstack(temp_array).reshape(img_height, img_width, n_slices, n_time, n_cells, order='F')\n",
    "        # Convert list in nested list\n",
    "        name_list = np.array(name_list).reshape(n_cells, n_time, n_slices)\n",
    "        return array5d, n_cells, name_list\n",
    "\n",
    "    def Convert6D(self, img_list, n_slices, n_time, n_channel=None):\n",
    "        \"\"\"\n",
    "        Input: A list with image path to all images, number of z-slices; Number of frames, n_channel.\n",
    "        Output: 6D array with (H x W x D x T x S x C) or (Y x X x Z x T x S x C).\n",
    "        Z refers to -slices, T refers to time points, S refers to Series/Cell, C refers to Channel.\n",
    "        \"\"\"\n",
    "        temp_array = []\n",
    "        name_list = []\n",
    "        n_cells = len(img_list)//(n_slices*n_time)\n",
    "        for i in range(len(img_list)):\n",
    "            mask, name_mask = self.LoadImageList(img_list, i)\n",
    "            # Read the image dimensions from first image\n",
    "            if i == 1:\n",
    "                # Image info\n",
    "                img_height = mask.shape[0] # Y\n",
    "                img_width = mask.shape[1] # X\n",
    "                temp_array.append(mask)\n",
    "                name_list.append(name_mask)\n",
    "            else:\n",
    "                temp_array.append(mask)\n",
    "                name_list.append(name_mask)\n",
    "        # Set Channel\n",
    "        if n_channel:\n",
    "            pass\n",
    "        else:\n",
    "            n_channel = 1\n",
    "        # use \"F\" Fortran for correct order\n",
    "        array6d = np.dstack(temp_array).reshape(img_height, img_width, n_slices, n_time, n_cells, n_channel, order='F')\n",
    "        \n",
    "        # Convert list in nested list\n",
    "        # name_list = np.array(name_list).reshape(n_cells, n_channel, n_time, n_slices)\n",
    "        return array6d, n_cells, name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OME_TIFF():\n",
    "    \"\"\"\n",
    "    Adapted from APEER: apeer-ometiff-library (https://github.com/apeer-micro/apeer-ometiff-library)\n",
    "    and CellProfiler: python-bioformats (https://github.com/CellProfiler/python-bioformats)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def read_ometiff(self, input_path):\n",
    "        \"\"\"\n",
    "        Read OME-TIFF\n",
    "        \"\"\"\n",
    "        import omexmlClass\n",
    "        import tifffile\n",
    "        with tifffile.TiffFile(input_path) as tif:\n",
    "            array = tif.asarray()\n",
    "            omexml_string = tif.ome_metadata\n",
    "\n",
    "        # Turn Ome XML String to an Bioformats object for parsing\n",
    "        metadata = omexmlClass.OMEXML(omexml_string)\n",
    "\n",
    "        # Parse pixel sizes\n",
    "        pixels = metadata.image(0).Pixels\n",
    "        size_c = pixels.SizeC\n",
    "        size_t = pixels.SizeT\n",
    "        size_z = pixels.SizeZ\n",
    "        size_x = pixels.SizeX\n",
    "        size_y = pixels.SizeY\n",
    "\n",
    "        # Expand image array to 5D of order (T, Z, C, X, Y)\n",
    "        if size_c == 1:\n",
    "            array = np.expand_dims(array, axis=-3)\n",
    "        if size_z == 1:\n",
    "            array = np.expand_dims(array, axis=-4)\n",
    "        if size_t == 1:\n",
    "            array = np.expand_dims(array, axis=-5)\n",
    "\n",
    "        # Makes sure to return the array in (T, Z, C, X, Y) order\n",
    "\n",
    "        dim_format = pixels.DimensionOrder\n",
    "\n",
    "        if dim_format == \"XYCZT\":\n",
    "            pass\n",
    "        elif dim_format == \"XYZCT\":\n",
    "            array = np.moveaxis(array, 1, 2)\n",
    "        elif dim_format == \"XYCTZ\":\n",
    "            array = np.moveaxis(array, 0, 1)\n",
    "        elif dim_format == \"XYZTC\":\n",
    "            array = np.moveaxis(array, 0, 2)\n",
    "        elif dim_format == \"XYTZC\":\n",
    "            array = np.moveaxis(array, 0, 2)\n",
    "            array = np.moveaxis(array, 0, 1)\n",
    "        elif dim_format == \"XYTCZ\":\n",
    "            array = np.moveaxis(array, 1, 2)\n",
    "            array = np.moveaxis(array, 0, 1)\n",
    "        else:\n",
    "            print(array.shape)\n",
    "            raise Exception(\"Unknow dimension format\") \n",
    "\n",
    "        return array, metadata, omexml_string\n",
    "\n",
    "    def update_omexml(self, omexml, Image_ID=None, Image_Name=None, Image_AcquisitionDate=None, \n",
    "                      DimensionOrder=None, dType=None, SizeT=None, SizeZ=None, SizeC=None, SizeX=None, SizeY=None,\n",
    "                      PhysicalSizeX=None, PhysicalSizeY=None, PhysicalSizeZ=None,\n",
    "                      ExposureTime=None,\n",
    "                      Channel_ID=None, Channel_Name=None, Channel_SamplesPerPixel=None):\n",
    "        \"\"\"\n",
    "        Update OME-XML with user input.\n",
    "        \"\"\"\n",
    "        import omexmlClass\n",
    "        metadata = omexmlClass.OMEXML(omexml)\n",
    "\n",
    "        if Image_ID:\n",
    "            metadata.image().set_ID(Image_ID)\n",
    "        if Image_Name:\n",
    "            metadata.image().set_Name(Image_Name)\n",
    "        if Image_AcquisitionDate:\n",
    "            metadata.image().Image.AcquisitionDate = Image_AcquisitionDate\n",
    "\n",
    "        if DimensionOrder: # Dimension order\n",
    "            metadata.image().Pixels.DimensionOrder = DimensionOrder\n",
    "        if dType: # The pixel bit type, for instance PT_UINT8\n",
    "            metadata.image().Pixels.PixelType = dType\n",
    "        if SizeT: # The dimensions of the image in the T direction in pixels\n",
    "            metadata.image().Pixels.set_SizeT(SizeT)\n",
    "        if SizeZ: # The dimensions of the image in the Z direction in pixels\n",
    "            metadata.image().Pixels.set_SizeZ(SizeZ)\n",
    "        if SizeC: # The dimensions of the image in the C direction in pixels\n",
    "            metadata.image().Pixels.set_SizeC(SizeC)\n",
    "        if SizeX: # The dimensions of the image in the X direction in pixels\n",
    "            metadata.image().Pixels.set_SizeX(SizeX)\n",
    "        if SizeY: # The dimensions of the image in the Y direction in pixels\n",
    "            metadata.image().Pixels.set_SizeY(SizeY)\n",
    "        if PhysicalSizeX: # The length of a single pixel in Y direction\n",
    "            metadata.image().Pixels.set_PhysicalSizeX(PhysicalSizeX)\n",
    "        if PhysicalSizeY: # The length of a single pixel in Y direction\n",
    "            metadata.image().Pixels.set_PhysicalSizeY(PhysicalSizeY)\n",
    "        if PhysicalSizeZ: # The length of a single pixel in Z direction\n",
    "            metadata.image().Pixels.set_PhysicalSizeZ(PhysicalSizeZ)\n",
    "\n",
    "        if ExposureTime: # Duration of exposure time in seconds\n",
    "            metadata.image().Plane.set_ExposureTime = ExposureTime\n",
    "        \n",
    "        if Channel_ID:\n",
    "            metadata.image().Channel.ID = Channel_ID\n",
    "        if Channel_Name:\n",
    "            metadata.image().Channel.Name = Channel_Name\n",
    "        if Channel_SamplesPerPixel:\n",
    "            metadata.image().Channel.SamplesPerPixel = Channel_SamplesPerPixel\n",
    "    \n",
    "        metadata = metadata.to_xml().encode()\n",
    "\n",
    "        return metadata\n",
    "\n",
    "\n",
    "    def gen_omexml(self, array):\n",
    "        \"\"\"\n",
    "        Generate OME-XML template\n",
    "        \"\"\"\n",
    "        import omexmlClass\n",
    "        \n",
    "        #Dimension order is assumed to be TZCYX\n",
    "        dim_order = \"TZCYX\"\n",
    "\n",
    "        metadata = omexmlClass.OMEXML()\n",
    "        shape = array.shape\n",
    "        assert ( len(shape) == 5), \"Expected array of 5 dimensions\"\n",
    "\n",
    "        metadata.image().set_Name(\"IMAGE\")\n",
    "        metadata.image().set_ID(\"0\")\n",
    "\n",
    "        pixels = metadata.image().Pixels\n",
    "        pixels.ome_uuid = metadata.uuidStr\n",
    "        pixels.set_ID(\"0\")\n",
    "\n",
    "        pixels.channel_count = shape[2]\n",
    "\n",
    "        pixels.set_SizeT(shape[0])\n",
    "        pixels.set_SizeZ(shape[1])\n",
    "        pixels.set_SizeC(shape[2])\n",
    "        pixels.set_SizeY(shape[3])\n",
    "        pixels.set_SizeX(shape[4])\n",
    "\n",
    "        pixels.set_DimensionOrder(dim_order[::-1])\n",
    "\n",
    "        pixels.set_PixelType(omexmlClass.get_pixel_type(array.dtype))\n",
    "\n",
    "        for i in range(pixels.SizeC):\n",
    "            pixels.Channel(i).set_ID(\"Channel:0:\" + str(i))\n",
    "            pixels.Channel(i).set_Name(\"C:\" + str(i))\n",
    "\n",
    "        for i in range(pixels.SizeC):\n",
    "            pixels.Channel(i).set_SamplesPerPixel(1)\n",
    "\n",
    "        pixels.populate_TiffData()\n",
    "\n",
    "        return metadata.to_xml().encode()\n",
    "\n",
    "\n",
    "\n",
    "    def write_ometiff(self, output_path, array, mode='minisblack', omexml_str = None):\n",
    "        \"\"\"\n",
    "        Write OME-TIFF.\n",
    "        \"\"\"\n",
    "        import tifffile\n",
    "        if omexml_str is None:\n",
    "            omexml_str = self.gen_omexml(array)\n",
    "\n",
    "        tifffile.imwrite(output_path, array,  photometric = mode, description=omexml_str, metadata = None)\n",
    "        return omexml_str\n",
    "    \n",
    "    \n",
    "    def write_omexml(self, path, omexml_str):\n",
    "        \"\"\"\n",
    "        Export for each cell an XML file (prettified).\n",
    "        \"\"\"\n",
    "        import xml.dom.minidom #Prettify XML\n",
    "        omexml_parse = xml.dom.minidom.parseString(omexml_str)\n",
    "        omexml_pretty = omexml_parse.toprettyxml()\n",
    "        \n",
    "        if path == 'print':\n",
    "            print(omexml_pretty) \n",
    "        else:\n",
    "            # Export XML\n",
    "            f =  open(path, \"wb\")\n",
    "            f.write(omexml_pretty.encode())\n",
    "            f.close()\n",
    "            print(omexml_pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Obtain properties and export predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(image_paths, \n",
    "            load_model, \n",
    "            condition, \n",
    "            object_size, \n",
    "            min_score, \n",
    "            time_lapse, \n",
    "            n_frames, \n",
    "            n_slices, \n",
    "            export_ome_tiff, \n",
    "            pixel_x=0, \n",
    "            pixel_y=0, \n",
    "            pixel_z=0):\n",
    "    \n",
    "    # ================= Setting parameters ================= #\n",
    "    convert_format = 1\n",
    "    pref_ext = '.png'\n",
    "    \n",
    "    # ================= IMPORT LIST OF FILES ================= #\n",
    "    # Check if it is a list\n",
    "    if isinstance(image_paths, list): \n",
    "        print(\"your object is a list !\") \n",
    "    else: \n",
    "        image_paths = [image_paths]\n",
    "    \n",
    "    # ================= CREATE OUTPUT DIR ================= #    \n",
    "    OUTPUT_DIR = 'output/'\n",
    "    if not os.path.exists( OUTPUT_DIR ):\n",
    "        # Main Folder\n",
    "        os.makedirs(  OUTPUT_DIR )\n",
    "        print('Output: ##### Create Output folder. #####')\n",
    "                \n",
    "    \n",
    "    file_type_list = []\n",
    "    #def load_image_list\n",
    "    image_list = []\n",
    "    for filepath in image_paths:\n",
    "        # Obtain filename\n",
    "        filename = os.path.basename(filepath)\n",
    "        # Keep file extension after first dot (.ome.tiff)\n",
    "        if filename.split(os.extsep, 1)[1].lower() == 'ome.tiff':\n",
    "            image_list.append(filepath)\n",
    "            file_type_list.append('ome-tiff')\n",
    "        elif os.path.splitext(filename)[1].lower() in ['.png', '.jpg', '.jpeg', '.tif']:\n",
    "            image_list.append(filepath)\n",
    "            file_type_list.append('tif-png')\n",
    "    # Sort list alphabetically (libary)\n",
    "    image_list = natsorted(image_list)\n",
    "\n",
    "    # Conver to a set (get unique values) to check if the file format is consistent\n",
    "    if len(set(file_type_list)) > 1:\n",
    "        sys.exit('Mixed file formats were imported.')\n",
    "    # Get file format of loaded images\n",
    "    file_type = list(set(file_type_list))[0]\n",
    "    \n",
    "    if file_type == 'ome-tiff':\n",
    "        filename_ome_list = []\n",
    "        # Use OME-TIFF loader\n",
    "        OME = OME_TIFF()\n",
    "        # Most efficient way to stack numpy in a loop is by append to list\n",
    "        ome_list = []\n",
    "        meta_list = []\n",
    "        for i, file in enumerate(image_list):\n",
    "            # Read OME-TIFF: T, Z, C, Y, X\n",
    "            ome_array, metadata, xml_str = OME.read_ometiff(file)\n",
    "            # Obtain filename\n",
    "            filename_ome_list.append(os.path.basename(file))\n",
    "            ome_list.append(ome_array)\n",
    "            meta_list.append(metadata)\n",
    "        # Convert list to 6D array: S, T, Z, C, Y, X\n",
    "        array6d_ome = np.stack(ome_list, axis=0)\n",
    "        array6d_ome.shape\n",
    "        # Meta data\n",
    "        pixel_x = meta_list[0].image(0).Pixels.get_PhysicalSizeX()\n",
    "        pixel_y = meta_list[0].image(0).Pixels.get_PhysicalSizeY()\n",
    "        pixel_z = meta_list[0].image(0).Pixels.get_PhysicalSizeZ()\n",
    "        \n",
    "        # Print meta data\n",
    "        print( 'Pixel size X: ' + str(pixel_x) )\n",
    "        print( 'Pixel size Y: ' + str(pixel_y) )\n",
    "        print( 'Pixel size Z: ' + str(pixel_z) )\n",
    "        \n",
    "        # Convert to SpinX 6D array format by permutation\n",
    "        # From: [S, T, Z, C, Y, X] to [Y, X, Z, T, S, C]\n",
    "        perm_ome_spinx = (4, 5, 2, 1, 0, 3 ) # Order\n",
    "\n",
    "        array6d_sx = np.transpose(array6d_ome, perm_ome_spinx)\n",
    "        array6d_sx.shape\n",
    "    else:\n",
    "        SX = SpinX()\n",
    "        array6d_sx, _, filename_img_list = SX.Convert6D(image_paths, n_slices, n_frames)\n",
    "    # ================= IMPORT LIST OF FILES END ================= #\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ================= MODEL IMPORT ================= #\n",
    "    # Check if user select pre-trained model\n",
    "    user_list = ['NA', 'na', 'Default', 'DEFAULT', '0']\n",
    "    # Load SpinX model if user types in 'Default' (or anything but an URL)\n",
    "    if load_model in user_list or len(load_model) < 10:\n",
    "    # Load default model\n",
    "        model_default = 1\n",
    "    else:\n",
    "        file_ext = '.h5'\n",
    "        # Extract model name\n",
    "        model_name = get_fname(load_model, file_ext)\n",
    "        \n",
    "        # Check file name format of the new model. Rename if needed.\n",
    "\n",
    "        model_name = check_model_name(model_file_name = model_name,\n",
    "                                      model_name = config.NAME) # Get name of the model from the config file\n",
    "        \n",
    "        \n",
    "        # Create folder for new model\n",
    "        out_name = config.NAME # Get name of the model from the config file\n",
    "        model_dir = os.path.join(MODEL_DIR,\n",
    "                                  out_name + '{}'.format(\n",
    "                                      datetime.datetime.now().\n",
    "                                      strftime(\"%Y%m%dT%H%M\")))\n",
    "        os.mkdir(model_dir)\n",
    "        # Download model and save it in the model folder\n",
    "        myfile = requests.get(load_model)\n",
    "        open(os.path.join(model_dir, model_name), 'wb').write(myfile.content)\n",
    "        model_default = 0\n",
    "        \n",
    "    # Create model in inference mode\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                              model_dir=MODEL_DIR,\n",
    "                              config=config)\n",
    "    \n",
    "    if model_default == 1:\n",
    "        # Find default model (first model)\n",
    "        weights_path = model.find_first()\n",
    "    else:\n",
    "        # Find latest model\n",
    "        weights_path = model.find_last()\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "    print(\"Loading model and weights completed.\")\n",
    "\n",
    "    # Obtain folder and file name to store in csv\n",
    "    # Get head of path\n",
    "    path_head = os.path.split(weights_path)[0]\n",
    "    # Get folder name (last position)\n",
    "    path_folder = os.path.split(path_head)[1]\n",
    "    # Get model name\n",
    "    path_name = os.path.split(weights_path)[1]\n",
    "    # Merge\n",
    "    model_path_name = os.path.join(path_folder, path_name)\n",
    "    # ================= MODEL IMPORT END ================= #\n",
    "\n",
    "    # User specification\n",
    "    df = pd.DataFrame(columns=['model_name',\n",
    "                               'filename',\n",
    "                               'img_height',\n",
    "                               'img_width',\n",
    "                               'img_dim',\n",
    "                               'cond_filt',\n",
    "                               'time_filt',\n",
    "                               'series',\n",
    "                               'time',\n",
    "                               'z-slice',\n",
    "                               'obj_id',\n",
    "                               'bbox_x1',\n",
    "                               'bbox_y1',\n",
    "                               'bbox_x2',\n",
    "                               'bbox_y2',\n",
    "                               'bbox_height',\n",
    "                               'bbox_width',\n",
    "                               'pred_runtime',\n",
    "                               'post_runtime',\n",
    "                               'excluded_obj'\n",
    "                              ])\n",
    "\n",
    "\n",
    "\n",
    "    ##### in progress\n",
    "    total_time = []\n",
    "    counter = 0\n",
    "    num_img = len(image_paths)\n",
    "    bad_obj_counter = 0\n",
    "\n",
    "    # Preallocate variables\n",
    "    bad_objects = []\n",
    "    \n",
    "    # For Timelapse\n",
    "    centroid_list = []\n",
    "    # Number of cells\n",
    "    N_cells = array6d_sx.shape[4]\n",
    "    list_break = np.arange(0, num_img, n_frames*n_slices)\n",
    "    cell_id = 0\n",
    "\n",
    "    # Set channel\n",
    "    ch = 0\n",
    "    \n",
    "    array6d_raw = [] # Store 6D array for raw\n",
    "    array6d_bin = [] # Store 6D array for binary\n",
    "    array6d_label = [] # Store 6D array for label\n",
    "    array6d_overlay = [] # Store 6D array for overlay    \n",
    "    \n",
    "    # Loop through Series [Y, X, Z, T, S, C]\n",
    "    for s in range(array6d_sx.shape[4]):\n",
    "        if file_type == 'ome-tiff':\n",
    "            filename = filename_ome_list[s]\n",
    "        elif file_type == 'tif-png':\n",
    "            filename = filename_img_list[counter]\n",
    "            \n",
    "        # Loop through Time [Y, X, Z, T, S, C]\n",
    "        for t in range(array6d_sx.shape[3]):\n",
    "            # Loop through Z-Slices [Y, X, Z, T, S, C]\n",
    "            for z in range(array6d_sx.shape[2]):\n",
    "                # Start timer\n",
    "                start = time.time()\n",
    "                print('counter var: ' + str(counter))\n",
    "                img =  array6d_sx[:,:,z,t,s,ch]\n",
    "                img_orig = np.array(img)\n",
    "                img_orig = img_as_ubyte(exposure.rescale_intensity(img_orig)) # Rescale uint16 to uint8\n",
    "                img_orig = grayToRgb(img_orig)\n",
    "                # Obtain image dimensions\n",
    "                img_height = img_orig.shape[0]\n",
    "                img_width = img_orig.shape[1]\n",
    "                img_dim = img_orig.shape[2]\n",
    "\n",
    "                # Prediction\n",
    "                results = model.detect([img_orig], verbose=1)\n",
    "                r = results[0]\n",
    "                if plot_on == 1:\n",
    "                    visualize.display_instances(img_orig, r['rois'], r['masks'], r['class_ids'], \n",
    "                                                dataset.class_names, r['scores'], title=\"Predictions\", figsize=(15,15))\n",
    "\n",
    "                # End timer\n",
    "                end = time.time()\n",
    "                e_time = end - start\n",
    "                print('Elapsed time for prediction: %f seconds' %(round(e_time,3)))\n",
    "                print() \n",
    "                print() \n",
    "                total_time.append(e_time)\n",
    "\n",
    "                # th-dataframe\n",
    "                df_line = pd.DataFrame(columns=['model_name',\n",
    "                                                'filename',\n",
    "                                                'img_height',\n",
    "                                                'img_width',\n",
    "                                                'img_dim',\n",
    "                                                'cond_filt',\n",
    "                                                'time_filt',\n",
    "                                                'series',\n",
    "                                                'time',\n",
    "                                                'z-slice',\n",
    "                                                'obj_id',\n",
    "                                                'bbox_x1',\n",
    "                                                'bbox_y1',\n",
    "                                                'bbox_x2',\n",
    "                                                'bbox_y2',\n",
    "                                                'bbox_height',\n",
    "                                                'bbox_width',\n",
    "                                                'pred_runtime',\n",
    "                                                'post_runtime',\n",
    "                                                'excluded_obj'\n",
    "                                               ])    \n",
    "\n",
    "                ### Loop through bounding boxes and masks (every mask has a bounding box)\n",
    "\n",
    "                # Create canvas for merging all masks (each value represents an instance) Note: A different data structure is needed for multiple classes\n",
    "                merged_mask = np.zeros((img_height, img_width), 'uint8')\n",
    "                # Create canvas for binary mask\n",
    "                binary_mask = np.zeros((img_height, img_width), 'uint8')\n",
    "\n",
    "                # Use conditional filtering\n",
    "                if condition == 1:\n",
    "                    if len(r['rois']) > 1:\n",
    "                        all_idx = []\n",
    "                        idx_to_clear = []\n",
    "                        area_array = []\n",
    "                        # Loop through detect ROIS\n",
    "                        for m in range(len(r['rois'])):\n",
    "                            all_idx.append(m)\n",
    "                            # Clear objects that are very close to the border\n",
    "                            bw_clear = imclearborder(r['masks'][:,:,m].astype('uint8'), 10)\n",
    "                            if np.sum(bw_clear)==0:\n",
    "                                # Store indices to be cleared\n",
    "                                idx_to_clear.append(m)\n",
    "\n",
    "\n",
    "                            # Keep only the object with the highest score\n",
    "                            if r['scores'][m] < min_score:\n",
    "                                idx_to_clear.append(m)\n",
    "\n",
    "                            # Check for area size\n",
    "                            props = regionprops(r['masks'][:,:,m].astype('uint8'))\n",
    "                            if user_profile == \"Spindle\":\n",
    "                                if props[0].area > object_size:\n",
    "                                    idx_to_clear.append(m)\n",
    "                            elif user_profile == \"CellMembrane\":\n",
    "                                if props[0].area < object_size:\n",
    "                                    idx_to_clear.append(m)\n",
    "                            area_array.append(props[0].area)\n",
    "                        # Find largest blob\n",
    "                        #max_value = max(area_array)\n",
    "                        #max_index = area_array.index(max_value)\n",
    "\n",
    "                        # Identify sublist from previous list and complete list\n",
    "                        #list_remaining = list(set(all_idx)^set(idx_to_clear))\n",
    "                        #to_remove = list(filter(lambda a: a != max_index, list_remaining))\n",
    "                        #idx_to_clear = idx_to_clear + to_remove\n",
    "\n",
    "                        ## Keep only unique ids\n",
    "                        idx_to_clear = list(set(idx_to_clear))\n",
    "                        bad_objects = len(idx_to_clear)\n",
    "                        r['rois'] = np.delete(r['rois'],idx_to_clear,0)\n",
    "                        r['class_ids'] = np.delete(r['class_ids'],idx_to_clear,0)\n",
    "                        r['scores'] = np.delete(r['scores'],idx_to_clear,0)\n",
    "                        r['masks'] = np.delete(r['masks'],idx_to_clear,2)\n",
    "                        # If empty array (repeat buy lower min_score requirement by 10%)\n",
    "                        if r['rois'].size == 0:\n",
    "                            # Re-run model on image\n",
    "                            results = model.detect([img_orig], verbose=1)\n",
    "                            r = results[0]\n",
    "                            if len(r['rois']) > 1:\n",
    "                                all_idx = []\n",
    "                                idx_to_clear = []\n",
    "                                area_array = []\n",
    "                                for m in range(len(r['rois'])):\n",
    "                                    all_idx.append(m)\n",
    "                                    # Clear objects that are very close to the border\n",
    "                                    bw_clear = imclearborder(r['masks'][:,:,m].astype('uint8'), 10)\n",
    "                                    if np.sum(bw_clear)==0:\n",
    "                                        # Store indices to be cleared\n",
    "                                        idx_to_clear.append(m)\n",
    "\n",
    "\n",
    "                                    # Keep only the object with the highest score\n",
    "                                    if r['scores'][m] <= min_score-(min_score*0.10):\n",
    "                                        idx_to_clear.append(m)\n",
    "\n",
    "                                    # Check for area size\n",
    "                                    props = regionprops(r['masks'][:,:,m].astype('uint8'))\n",
    "                                    if user_profile == \"Spindle\":\n",
    "                                        if props[0].area > object_size:\n",
    "                                            idx_to_clear.append(m)\n",
    "                                    elif user_profile == \"CellMembrane\":\n",
    "                                        if props[0].area < object_size:\n",
    "                                            idx_to_clear.append(m)\n",
    "                                    area_array.append(props[0].area)\n",
    "                                # Find largest blob\n",
    "                                #max_value = max(area_array)\n",
    "                                #max_index = area_array.index(max_value)\n",
    "\n",
    "                                # Identify sublist from previous list and complete list\n",
    "                                #list_remaining = list(set(all_idx)^set(idx_to_clear))\n",
    "                                #to_remove = list(filter(lambda a: a != max_index, list_remaining))\n",
    "                                #idx_to_clear = idx_to_clear + to_remove\n",
    "\n",
    "                                ## Keep only unique ids\n",
    "                                idx_to_clear = list(set(idx_to_clear))\n",
    "                                bad_objects = len(idx_to_clear)\n",
    "                                r['rois'] = np.delete(r['rois'],idx_to_clear,0)\n",
    "                                r['class_ids'] = np.delete(r['class_ids'],idx_to_clear,0)\n",
    "                                r['scores'] = np.delete(r['scores'],idx_to_clear,0)\n",
    "                                r['masks'] = np.delete(r['masks'],idx_to_clear,2)\n",
    "                    else:\n",
    "                        bad_objects = 0\n",
    "\n",
    "                if time_lapse == 1:\n",
    "                    idx_to_clear_time = []\n",
    "                    dist_list = []\n",
    "                    all_idx_time = []\n",
    "                    # Check if ROI exists\n",
    "                    if r['rois'].size > 0:\n",
    "                        props_cen = regionprops(r['masks'].astype('uint8'))\n",
    "                        yx_centroid = [props_cen[0].centroid[0], props_cen[0].centroid[1]]\n",
    "                        centroid_list.append(yx_centroid)\n",
    "                        if t == 0:\n",
    "                            # Change based on number of cells\n",
    "                            cell_id += 1\n",
    "                        else:\n",
    "                            for n in range(len(r['rois'])):\n",
    "                                all_idx_time.append(n)\n",
    "                                current = regionprops(r['masks'][:,:,n].astype('uint8'))\n",
    "                                current_yx = [current[0].centroid[0], current[0].centroid[1]]\n",
    "\n",
    "\n",
    "                                y1 = current_yx[0]\n",
    "                                y2 = centroid_list[t-1][0]\n",
    "                                x1 = current_yx[1]\n",
    "                                x2 = centroid_list[t-1][1]\n",
    "\n",
    "                                dist = np.sqrt( (x2 - x1)**2 + (y2 - y1)**2 )\n",
    "                                dist_list.append(dist)\n",
    "\n",
    "                            min_dist = min(dist_list)\n",
    "                            min_dist_idx = dist_list.index(min_dist)\n",
    "                            filt_idx_time = list(filter(lambda a: a != min_dist_idx, all_idx_time))\n",
    "                            r['rois'] = np.delete(r['rois'],filt_idx_time,0)\n",
    "                            r['class_ids'] = np.delete(r['class_ids'],filt_idx_time,0)\n",
    "                            r['scores'] = np.delete(r['scores'],filt_idx_time,0)\n",
    "                            r['masks'] = np.delete(r['masks'],filt_idx_time,2)\n",
    "                            bad_objects = bad_objects + len(filt_idx_time)\n",
    "                    else:\n",
    "                        yx_centroid = []  \n",
    "                        centroid_list.append(yx_centroid)\n",
    "\n",
    "\n",
    "                # Obtain tensor with masks (format: H x W x instances)\n",
    "                mask_tensor = r['masks']\n",
    "                # Number of objects\n",
    "                num_obj = mask_tensor.shape[2]\n",
    "                # Obtain tensor with bounding boxes (format: NUMBER OF OBJECTS x (y1, x1, y2, x2))\n",
    "                bbox_tensor = r['rois']\n",
    "                # Total number of bounding boxes\n",
    "                num_bbox = len(bbox_tensor)\n",
    "\n",
    "\n",
    "                if num_bbox > 0:\n",
    "                    # Loop through instances\n",
    "                    for jj in range(0, num_bbox):\n",
    "                        # Original format of bounding box: y1, x1, y2, x2\n",
    "                        th_bbox = r['rois'][jj]\n",
    "                        # Re-order coordinates\n",
    "                        x1 = th_bbox[1]\n",
    "                        y1 = th_bbox[0]\n",
    "                        x2 = th_bbox[3]\n",
    "                        y2 = th_bbox[2]\n",
    "\n",
    "                        # Calculate the bounding box dimensions\n",
    "                        bbox_height = x2 - x1\n",
    "                        bbox_width = y2 - y1        \n",
    "                        # Write data to dataframe\n",
    "                        #df_line.loc[jj] = model_path_name, filename, img_height, img_width, img_dim, jj, x1, y1, x2, y2, bbox_height, bbox_width, e_time, 0, 0, 0, bad_objects\n",
    "\n",
    "\n",
    "                        ### MASK\n",
    "                        # Take th mask from the tensor\n",
    "                        th_mask = mask_tensor[:, :, jj]\n",
    "                        # Convert true/false to image\n",
    "                        th_mask_img = th_mask.astype(np.uint8)\n",
    "                        th_mask_img*= 255\n",
    "\n",
    "                        # Assign value if the th-mask is 1\n",
    "                        merged_mask[th_mask_img==255] = jj + 1\n",
    "\n",
    "                        # Create binary\n",
    "                        binary_mask[th_mask_img==255] = 255\n",
    "                else:\n",
    "                    jj = []\n",
    "                    x1 = []\n",
    "                    y1 = []\n",
    "                    x2 = []\n",
    "                    y2 = []\n",
    "                    bbox_height = []\n",
    "                    bbox_width = []\n",
    "\n",
    "                # Sort dataframe by obj_id\n",
    "                df_line.sort_values(by=['obj_id'])\n",
    "                # Append dataframe for each image\n",
    "                df = df.append(df_line)\n",
    "                \n",
    "                # Create overlay\n",
    "                # Binarize image\n",
    "                bw = binarize(merged_mask)\n",
    "\n",
    "                # Delete border connected to image border\n",
    "                label_image = label(bw)\n",
    "                image_label_overlay = label2rgb(label_image, image=img_orig, image_alpha = 0.6, bg_label = 0)\n",
    "                # Rescale overlay\n",
    "                img_overlay = image_label_overlay*255\n",
    "                img_overlay = img_overlay.astype('uint8')\n",
    "                # Export merged mask\n",
    "                \n",
    "\n",
    "                # Append to 6D array (for OME-TIFF)\n",
    "                # Rescale raw image\n",
    "                img_raw = rgb2gray(img_orig)*255\n",
    "                img_raw = img_raw.astype('uint8')\n",
    "                # For 6D array\n",
    "                array6d_raw.append(img_raw) # Raw 6D\n",
    "                array6d_bin.append(binary_mask) # Binary 6D\n",
    "                array6d_label.append(merged_mask) # Label 6D\n",
    "                array6d_overlay.append(img_overlay) # Overlay 6D  \n",
    "\n",
    "        \n",
    "                end_2 = time.time()\n",
    "                post_time = end_2 - end\n",
    "                print('Elapsed time for post-processing: %f seconds' %(round(post_time,3)))\n",
    "                # Write data to dataframe\n",
    "                df_line.loc[0] = model_path_name, filename, img_height, img_width, img_dim, condition, time_lapse, s, t, z, jj, x1, y1, x2, y2, bbox_height, bbox_width, e_time, post_time, bad_objects\n",
    "                df = df.append(df_line)\n",
    "\n",
    "                counter += 1\n",
    "        \n",
    "    \n",
    "    # Reshape 6d array to OME-TIFF Format: [S, T, Z, C, Y, X] from SpinX [Y, X, Z, T, S, C]\n",
    "    # Raw ( Don't use order='F' for a reshaping non 1D array - use it for 1D only)\n",
    "    array6d_raw = np.array(array6d_raw).reshape(array6d_sx.shape[4], array6d_sx.shape[3], array6d_sx.shape[2], array6d_sx.shape[5], array6d_sx.shape[0] , array6d_sx.shape[1])\n",
    "    # Binary\n",
    "    array6d_bin = np.array(array6d_bin).reshape(array6d_sx.shape[4], array6d_sx.shape[3], array6d_sx.shape[2], array6d_sx.shape[5], array6d_sx.shape[0] , array6d_sx.shape[1])\n",
    "    # Label\n",
    "    array6d_lab = np.array(array6d_label).reshape(array6d_sx.shape[4], array6d_sx.shape[3], array6d_sx.shape[2], array6d_sx.shape[5], array6d_sx.shape[0] , array6d_sx.shape[1])\n",
    "    # Overlay (The overlay is a RGB. Hence, the dimensions are now: STZYXC with C = 3)\n",
    "    array6d_overlay = np.array(array6d_overlay).reshape(array6d_sx.shape[4], array6d_sx.shape[3], array6d_sx.shape[2], array6d_sx.shape[0] , array6d_sx.shape[1], 3)\n",
    "    \n",
    "    \n",
    "    # =========== EXPORT =========== #\n",
    "    # Preallocate\n",
    "    output_raw = [] # Store output raw images here\n",
    "    output_binary = [] # Store output binary images here\n",
    "    output_label = [] # Store output label images here\n",
    "    output_overlay = [] # Store output overlay images here\n",
    "    \n",
    "    # Export individual images from 6D array\n",
    "    # Create folder structure\n",
    " \n",
    "    list_dir_raw = os.path.join(OUTPUT_DIR, 'raw')\n",
    "    if not os.path.exists( list_dir_raw ):\n",
    "        # Main Folder\n",
    "        os.makedirs( list_dir_raw )\n",
    "        print('Output: ##### Create raw input folder. #####')\n",
    "\n",
    "    list_dir_bin = os.path.join(OUTPUT_DIR, 'binary')\n",
    "    if not os.path.exists( list_dir_bin ):\n",
    "        # Main Folder\n",
    "        os.makedirs( list_dir_bin )\n",
    "        print('Output: ##### Create binary output folder. #####')\n",
    "\n",
    "    list_dir_lab = os.path.join(OUTPUT_DIR, 'label')\n",
    "    if not os.path.exists( list_dir_lab ):\n",
    "        # Main Folder\n",
    "        os.makedirs( list_dir_lab )\n",
    "        print('Output: ##### Create label output folder. #####')\n",
    "\n",
    "    list_dir_overlay = os.path.join(OUTPUT_DIR, 'overlay')\n",
    "    if not os.path.exists( list_dir_overlay ):\n",
    "        # Main Folder\n",
    "        os.makedirs( list_dir_overlay )\n",
    "        print('Output: ##### Create overlay output folder. #####')\n",
    "            \n",
    "    # If user wants to export as OME-TIFF\n",
    "    if export_ome_tiff == 1:\n",
    "        # Use OME-TIFF loader\n",
    "        OME = OME_TIFF()\n",
    "        # Loop through Series [S, T, Z, C, Y, X]\n",
    "        for s in range(array6d_raw.shape[0]):\n",
    "            print('Series ' + str(s) )\n",
    "            # Get 5D array and write output as multi-page OME-TIFF files\n",
    "            array5d_raw = array6d_raw[s,:,:,:,:,:]\n",
    "            array5d_bin = array6d_bin[s,:,:,:,:,:]\n",
    "            array5d_label = array6d_lab[s,:,:,:,:,:]\n",
    "            array5d_overlay = array6d_overlay[s,:,:,:,:,:]\n",
    "            \n",
    "            if file_type == 'ome-tiff':\n",
    "                # Get OME-TIFF file name and extension\n",
    "                ome_tiff_name = filename_ome_list[s].split(os.extsep, 1)[0]\n",
    "                ext = '.' + filename_ome_list[s].split(os.extsep, 1)[1]\n",
    "            elif file_type == 'tif-png':\n",
    "                ome_tiff_name = filename_img_list[s*n_frames*n_slices].split(os.extsep, 1)[0]\n",
    "                ext = '.ome.tiff'\n",
    "            \n",
    "            ome_tiff_name_raw = ome_tiff_name + ext\n",
    "            ome_tiff_name_binary = ome_tiff_name + '_BINARY' + ext\n",
    "            ome_tiff_name_label = ome_tiff_name + '_LABEL' + ext\n",
    "            ome_tiff_name_overlay = ome_tiff_name + '_OVERLAY' + ext\n",
    "            # Generate OME-XML template\n",
    "            omexml_temp = OME.gen_omexml(array5d_bin)\n",
    "            # Update OME-XML\n",
    "            omexml_upd = OME.update_omexml(omexml_temp, PhysicalSizeX=pixel_x, PhysicalSizeY=pixel_y, PhysicalSizeZ=pixel_z)\n",
    "            # Write OME-TIFF\n",
    "            omexml_new = OME.write_ometiff(os.path.join(list_dir_raw, ome_tiff_name_raw), array5d_raw, mode='minisblack', omexml_str = omexml_upd)\n",
    "            _ = OME.write_ometiff(os.path.join(list_dir_bin, ome_tiff_name_binary), array5d_bin, mode='minisblack', omexml_str = omexml_upd)\n",
    "            _ = OME.write_ometiff(os.path.join(list_dir_lab, ome_tiff_name_label), array5d_label, mode='minisblack', omexml_str = omexml_upd)\n",
    "            _ = OME.write_ometiff(os.path.join(list_dir_overlay, ome_tiff_name_overlay), array5d_overlay, mode='rgb', omexml_str = omexml_upd)\n",
    "            # Export OME-XML\n",
    "            OME.write_omexml(os.path.join(OUTPUT_DIR, ome_tiff_name +'.xml'), omexml_new)\n",
    "            # Store full path for export\n",
    "            output_raw.append(ome_tiff_name_raw)\n",
    "            output_binary.append(ome_tiff_name_binary)\n",
    "            output_label.append(ome_tiff_name_label)\n",
    "            output_overlay.append(ome_tiff_name_overlay)\n",
    "    else:\n",
    "        counter_export = 0 # Counting index for list export\n",
    "        # Loop through Series [S, T, Z, C, Y, X]\n",
    "        for s in range(array6d_raw.shape[0]):\n",
    "            # Loop through Times [S, T, Z, C, Y, X]\n",
    "            for t in range(array6d_raw.shape[1]):\n",
    "                # Loop through Z-slices [S, T, Z, C, Y, X]\n",
    "                for z in range(array6d_raw.shape[2]):\n",
    "                    img_raw = array6d_raw[s,t,z,ch,:,:] # Raw\n",
    "                    img_bin = array6d_bin[s,t,z,ch,:,:] # Binary\n",
    "                    img_lab = array6d_lab[s,t,z,ch,:,:] # Label\n",
    "                    img_overlay = array6d_overlay[s,t,z,:,:,:] # Overlay\n",
    "                    # Obtain filename is different for OME-TIFF and list of TIF\n",
    "                    if file_type == 'ome-tiff':\n",
    "                        filename_export_list = filename_ome_list[s].split(os.extsep, 1)[0] + '_s' + str(s) + '_t' + str(t) + '_z' + str(z)\n",
    "                        # Export raw image as single tif\n",
    "                        filename_export_list_raw = filename_export_list + '.tif'\n",
    "                    elif file_type == 'tif-png':\n",
    "                        filename_export_list = os.path.splitext(os.path.basename(filename_img_list[counter_export]))[0]\n",
    "                        # Export raw image as single tif\n",
    "                        filename_export_list_raw = filename_export_list + '.tif'\n",
    "                        \n",
    "                    filename_export_list_binary = filename_export_list + '_BINARY' + pref_ext\n",
    "                    filename_export_list_label = filename_export_list + '_LABEL' + pref_ext\n",
    "                    filename_export_list_overlay = filename_export_list + '_OVERLAY' + pref_ext\n",
    "\n",
    "                    # Export\n",
    "                    cv2.imwrite(os.path.join(list_dir_raw, filename_export_list_raw), img_raw) # Binary\n",
    "                    cv2.imwrite(os.path.join(list_dir_bin, filename_export_list_binary), img_bin) # Binary\n",
    "                    cv2.imwrite(os.path.join(list_dir_lab, filename_export_list_label), img_lab) # Label\n",
    "                    cv2.imwrite(os.path.join(list_dir_overlay, filename_export_list_overlay), img_overlay) # Overlay\n",
    "                    # Store full path for export\n",
    "                    output_raw.append( os.path.join(list_dir_raw, filename_export_list_raw) )\n",
    "                    output_binary.append( os.path.join(list_dir_bin, filename_export_list_binary) )\n",
    "                    output_label.append( os.path.join(list_dir_lab, filename_export_list_label) )\n",
    "                    output_overlay.append( os.path.join(list_dir_overlay, filename_export_list_overlay) )\n",
    "                    counter_export += 1\n",
    "     \n",
    "    # Convert seconds to hh:mm:ss\n",
    "    hours, seconds =  sum(total_time) // 3600, sum(total_time) % 3600\n",
    "    minutes, seconds = sum(total_time) // 60, sum(total_time) % 60\n",
    "\n",
    "    # Runtime calculations\n",
    "    total_runtime = str(f\"{round(hours):02d}\" + \"h \" + f\"{round(minutes):02d}\" + \"mins \" + f\"{round(seconds):02d}\" + \"secs\")\n",
    "    avg_runtime = str( round(sum(total_time)/len(total_time),3) ) + \" seconds\"\n",
    "    # Variances cant be computed with only 1 value (assigned to 0)\n",
    "    if len(total_time) < 2:\n",
    "        var_runtime = str(0) + \" seconds\"\n",
    "    else:\n",
    "        var_runtime = str( round(stdev(total_time), 3) ) + \" seconds\"\n",
    "\n",
    "        # Change alignment for adding more columns 'c'\n",
    "    pred_tab = tt.to_string(\n",
    "        [[ num_img, total_runtime, avg_runtime, var_runtime ]],\n",
    "        header=[\"N\", \"Total prediction time:\", \"Avg. prediction time for one image\", \"SD of prediction time:\"],\n",
    "        style=tt.styles.ascii_thin_double,\n",
    "        alignment=\"lccr\",\n",
    "        # padding=(0, 1),\n",
    "    )\n",
    "    print(pred_tab)\n",
    "\n",
    "    # Assign runtime\n",
    "    #df['total_pred_runtime'] = total_time[0]\n",
    "\n",
    "\n",
    "    # Export dataframe to .csv\n",
    "    csv_filename = \"{}{:%Y%m%dT%H%M}.csv\".format(\"summaryTable_\", datetime.datetime.now())\n",
    "    df.to_csv(os.path.join(OUTPUT_DIR, csv_filename), index=False)\n",
    "    \n",
    "    # Delete if new model was imported\n",
    "    if model_default == 0:\n",
    "        # Delete downloaded file once executed\n",
    "        shutil.rmtree(model_dir)\n",
    "    \n",
    "    print('=== SpinX AI: Completed ===')\n",
    "    \n",
    "    # Create a ZIP file of the OUTPUT_DIR\n",
    "    print('=== Export as ZIP archive: Start ===')\n",
    "    # Destination of ZIP file (in ROOT DIR)\n",
    "    output_zip_name = 'spinx_ai_output'\n",
    "    shutil.make_archive(output_zip_name, 'zip', OUTPUT_DIR)\n",
    "    output_zip_name_full = output_zip_name + '.zip'\n",
    "    print('=== Export as ZIP archive: Completed ===')\n",
    "    return {'output_zip': output_zip_name_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multiple objects (OME-TIFF)\n",
    "# execute(\n",
    "#     image_paths = [\n",
    "#     'input_ome_tiff/exp2020-026-set001_hela_his2b-gfp_mcherry-tubulin_mg132-10uM_01-07-DMSO_08-19-MARK2i-10uM01_17_R3D_EQT_w605_t01_z1.ome.tiff',\n",
    "#     'input_ome_tiff/exp2020-026-set001_hela_his2b-gfp_mcherry-tubulin_mg132-10uM_01-07-DMSO_08-19-MARK2i-10uM01_18_R3D_EQT_w605_t01_z1.ome.tiff'\n",
    "#     ],\n",
    "#     load_model = 'NA',\n",
    "#     condition = 1, \n",
    "#     object_size = 20000, \n",
    "#     min_score = 0.92, \n",
    "#     time_lapse = 1, \n",
    "#     n_frames = 5, \n",
    "#     n_slices = 3, \n",
    "#     export_ome_tiff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiple objects (LIST)\n",
    "#\n",
    "#input_dir = 'input'\n",
    "#list_full = os.listdir(input_dir)\n",
    "## Sort list\n",
    "#list_full = natsorted(list_full)\n",
    "#list_filt = []\n",
    "#for fp in list_full:\n",
    "#    if os.path.splitext(fp)[1] in ['.png', '.jpg', '.jpeg', '.tif']:\n",
    "#            list_filt.append(os.path.join(input_dir, fp))\n",
    "#\n",
    "#\n",
    "#execute(\n",
    "#    image_paths = list_filt,\n",
    "#    load_model = 'NA',\n",
    "#    condition = 1, \n",
    "#    object_size = 20000, \n",
    "#    min_score = 0.92, \n",
    "#    time_lapse = 1, \n",
    "#    n_frames = 5, \n",
    "#    n_slices = 3, \n",
    "#    export_ome_tiff = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_env]",
   "language": "python",
   "name": "conda-env-ml_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
